\documentclass[12pt]{article}

\pdfminorversion=4

%%% IN THE FINAL VERSION, THE INPUT HEADER FILE SHOULD BE PASTED IN.
%\input{header-thesis.tex}

\usepackage{amsmath,amssymb}
\usepackage{graphicx,psfrag,epsf}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{caption}
\usepackage{Sweave}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{url} % not crucial - just used below for the URL
\usepackage{float}
\usepackage{indentfirst}
\usepackage{makecell}
\usepackage{hyphenat}
\newcommand\myeqref[1]{(\ref{#1})}
\captionsetup[figure]{font=small,labelfont=bf}
\captionsetup[table]{font=small,labelfont=bf}

\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{1}

\DeclareSymbolFont{matha}{OML}{txmi}{m}{it}% txfonts
\DeclareMathSymbol{\varv}{\mathord}{matha}{118}

\usepackage{fullpage}
% DON'T change margins - should be 1 inch all around.
%\addtolength{\oddsidemargin}{-.5in}%
%\addtolength{\evensidemargin}{-.5in}%
%\addtolength{\textwidth}{1in}%
%\addtolength{\textheight}{-.3in}%
%%\addtolength{\textheight}{.3in}%
%\addtolength{\topmargin}{-.8in}%

\bibliographystyle{plain}

% to run code from R: knitr::purl("ms.Rnw") ; source("ms.R")

<<set-opts,include=F,cache=F,echo=FALSE>>=
options(
        scipen=2,
        help_type="html",
        stringsAsFactors=FALSE,
        prompt="R> ",
        continue="+  ",
        width=70,
        useFancyQuotes=FALSE,
        reindent.spaces=2,
        xtable.comment=FALSE
        )
@

<<knitr-opts,include=F,cache=F,purl=F,echo=FALSE>>=
library("knitr")
opts_knit$set(concordance=TRUE)
opts_chunk$set(
    progress=TRUE,prompt=TRUE,highlight=FALSE,
    tidy=TRUE,
    tidy.opts=list(
        keep.blank.line=FALSE
    ),
    comment="",
    warning=FALSE,
    message=FALSE,
    error=TRUE,
    echo=TRUE,
    cache=FALSE,
    strip.white=TRUE,
    results="tex",
    background="#FFFFFF00",
    size="normalsize",
    fig.path="figure/",
    fig.lp="fig:",
    fig.align="left",
    fig.show="asis",
#    dpi=300,
    dev="pdf",
    dev.args=list(
        bg="transparent",
        pointsize=9
    )
)
@

% \SweaveOpts{concordance=TRUE}

\date{This manuscript was compiled on \today}

\begin{document}
\SweaveOpts{concordance=TRUE}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\thispagestyle{plain}
\begin{center}
    \Large
    \textbf{On the Transmissibility of Cholera During the 2010-2019 Haiti Cholera Epidemic}
        
    \vspace{0.1cm}
    \large
    A Study in Simulation-Based Inference for Infectious Disease Transmission
        
    \vspace{0.4cm}
    \textbf{Kevin Tan, Noah Treutle, Jesse Wheeler, Edward Ionides}
    
    \vspace{0.2cm}
    Department of Statistics, University of Michigan
       
    \vspace{0.9cm}
\end{center}

\begin{abstract}
During an epidemic, competent governments often take many measures are taken to mitigate the spread of the disease and flatten the curve. 
These measures may include sanitation and hygiene improvements, more accurate monitoring of cases, social distancing, education campaigns, vaccination, and many more. 
Should these measures be successful, one could expect a decrease in the effective transmissibility of the disease as time goes on. 
SEIR models are a common method for modeling epidemics, however this is a nontrivial task as these models can easily mask the effect of interventions. Existing models, such as the ones featured in Lee et. al. \cite{Lee_haiticholera}, do not attempt to factor in the possibility of a trend and numerous confounding factors such as the depletion of the susceptible population make the detection of a trend in effective transmissibility a challenging statistical endeavor.
As such, we attempt to detect a trend in the transmissibility of cholera during the 2010-2019 cholera epidemic in Haiti. 
Ultimately, we find evidence for a decreasing trend in the transmissibility of cholera based on the first model featured in Lee et al. \cite{Lee_haiticholera}, via estimating model parameters via simulation-based inference as in \cite{Ionides_if}, and then performing a hypothesis test via Monte-Carlo profile confidence intervals on the trend parameter \cite{Ionides_mcap}. 
We also detect seasonality in the transmissibility of cholera corresponding to seasonality in rainfall throughout the year. 

%if jesse doesn't want it, we can eat up the claim that cholera would go away regardless?
%why would this be relevant to epidemiology? could it suggest wash effectiveness? put into context about what is known about wash interventions
% also a tutorial/applied stats case study for epi people on hypothesis testing with the mcap and nested models, careful methods section
%   would need supplement on how model is developed according to the highest standards we can manage of reproducibility and transparency, how-to-basic e.g. sbied polio, likely do it in supplement
% plos comp bio, epidemics
%imagine writing for somewhere in between an applied stats and an epi audience

%else, if doing applied statistics, then focus on more methodological concerns

\end{abstract}

\vfill

\noindent All materials and code can be downloaded at \url{https://github.com/hetankevin/haitiwash}.

\newpage

\spacingset{1.25} % DON'T change the spacing!

\section{Introduction}

  The cholera epidemic in Haiti began in October 2010, when soldiers from the UN Stabilization Mission introduced the bacteria to the island, during their response to an earthquake in January 2010. 
  The epidemic lasted several years, ending in 2019, but not before claiming almost 10,000 lives and infecting over 800,000 people \cite{Lee_haiticholera}. 
  
  Lee et al. \cite{Lee_haiticholera} suggested in 2020 that nationwide vaccination rollouts would be necessary for cholera to be fully eradicated in Haiti despite case numbers significantly dropping in 2019, and supported their claim with forecasts from their stochastic epidemiological models.
  Haiti never managed to mount a widespread vaccination campaign, due to limited stockpiles and prohibitive costs \cite{rebaudet}. 
  Contrary to their predictions, cholera never returned to Haiti after 2019, with Haiti declared free of cholera on February 4 2022 (cite). 
  
  This observation is puzzling at first glance. 
  However, noting that numerous measures other than vaccination, such as water, sanitation and hygiene improvements (cite), more rapid medical care, monitoring and testing (cite), and education campaigns (cite) were taken within that time period, suggests a conjecture. 
  We suggest here that measures including but not limited to those mentioned above might have induced a decreasing trend in the transmissibility of cholera in Haiti from 2010 to 2019, and if this is evidenced in the data, the eradication of the disease in Haiti would not be surprising in that light. 
  To that end, we attempt to detect a trend in the transmissibility of cholera in Haiti during this time period, through fitting a stochastic compartmental SEIR model adapted from Lee et al \cite{Lee_haiticholera} and (citeAnna), augmenting it with an additional trend parameter, and then conducting a hypothesis test on these two nested models with the recent methodology of Ionides et. al. \cite{Ionides_mcap}.


\section{Background}

  %more stochastic seir compartmental models, particle filtering, if2 , etc. also would pomp get a lot more users/citations if everyone started calling hidden markov models for the MLers

 In many epidemiological settings, statistical modelling can be of immense use in motivating public health decision-making. For example, modelling reported cases of a given infectious disease can help inform the subsequent actions taken to mitigate the disease's spread. Due to the inherent randomness and complexity of population dynamics, there are numerous different methods for modelling disease, all of which have advantages and disadvantages. Yet the contributions of epidemiological models to our understanding of how infectious diseases evolve in a population are of high value, and it is worth tackling the challenge of developing a good and useful model.
  
  It is well established that state\hyp{}space models are appropriate and effective models when studying environmental and biological processes. At its core, a state\hyp{}space model has two components: an unobserved state process and a dependent observation process \cite{Ionides_infdynsys}. The ability to use a state\hyp{}space model to inform policy and public action depends upon the model's quality, which itself is dependent upon the ease of statistical inference with respect to the model's parameters. Fortunately several methods have been developed to facilitate estimation of unknown parameter values, one of which is maximum likelihood via iterated filtering (MIF) proposed by Ionides et al., a variant of which is addressed in \hyperref[sec:like]{section 2.3} \cite{Ionides_if}.
  
  Compartment models are another standard tool for modelling infectious diseases. By dividing a population into compartments, for example as (S)usceptible, (I)nfectious, (R)ecovered in the standard SIR compartment model, the spread of a disease can be described with much more specificity because attention is given to all stages of host infection. However, it is nearly impossible to know how many individuals populate a compartment or are transitioning between compartments at a given time. To overcome this uncertainty, compartment models can be coupled with state\hyp{}space models to form a comprehensive representation of a disease's progression in which parameters can be more easily estimated via inference methods for state\hyp{}space models. In the next few sections, we provide a brief overview of the foundational concepts needed to understand these models.

\subsection{Time Series and Markov Processes}

 Consider a sequence of $N$ time points, $t_{1:N} = \{ t_1, t_2, \dots, t_N \}$, and a sequence of $N$ observations made at each time point, $y_{1:N} = \{ y_{t_1}, y_{t_2}, \dots, y_{t_N} \}$. We call $Y_{1:N}$ a time series model with jointly defined random variables $Y_n$, \hspace{1mm} $\forall n \in 1:N$, and we can conceive of the data, $y_{1:N}$, as one realization of $Y_{1:N}$ \cite{Shumway_ch1}.
  
  We then describe a time series model, $X_{1:N}$, where $X_n = X(t_n)$ is a random process at time $n$, \hspace{1mm} $\forall n \in 1:N$. Should this time series model satisfy the condition that its state at time $n + 1$ is conditional only on its state at time $n$, $X_{1:N}$ is called a Markov process model. Mathematically, this can be represented as the following equation stating that the conditional density of the process $X_n$ given the processes $X_{1:n-1}$ is equivalent to the conditional density given only the process $X_{n-1}$ \cite{cham}:
        \begin{equation}
        f_{X_n|X_{1:n-1}}(x_n|x_{1:n-1}) = f_{X|X_{n-1}}(x_n|x_{n-1})
        \end{equation}

\subsection{Partially Observed Markov Processes}

 Often the details of the mechanisms underlying the evolution of a natural system are unknown. In epidemiology, the exact number of individuals exposed to disease at a given time is usually unknown. We can work around the issue of missing information using partially observed Markov (POMP) models. We create a POMP model by joining two processes, one that is unobservable (latent) but of interest and one that is observable and dependent upon the first.
  
  Let the random variables $X_{1:N}$ represent the latent state process where $X_1$ serves to initialize the process model, $f_{X|X_{n-1}}(x_n|x_{n-1})$. With the random variables $Y_{1:N}$ representing the observable measurement process, the measurement model is $f_{Y_n|X_n}(y_n|x_n)$, and the collected data $y_{1:N}$ are observations of this process. We assume that each $Y_n$ depends only upon the latent process at time $n$, $X_n$, and is conditionally independent of the other variables representing the measurement and latent processes, $Y_m$ and $X_m$, \hspace{1mm} $\forall m \in 1:N,$ \hspace{1mm} $m \ne n$ \cite{Shumway_ch6}. Together, $X_{1:N}$ and $Y_{1:N}$ form our POMP model.

\subsection{Likelihood and Iterated Filtering}
\label{sec:like}

 In problems of statistical inference, it is common to use likelihood to inform parameter estimation and model selection. Given a model parameterized by vector $\theta$ in the $m$-dimensional parameter space $\Theta_m$, the likelihood function is the joint probability density of the data, $y_{1:N}$, at $\theta$:
        \begin{equation}
        \mathcal{L}(\theta) = f_{Y_{1:N}}(y_{1:N}; \theta)
        \end{equation}
        
  We then aim to find an estimate of $\theta$, $\hat{\theta}$, which maximizes this function, $\mathcal{L}(\hat{\theta})$, or its natural logarithm, $\mathbf{\ell}(\hat{\theta})$ \cite{Millar}. 
  
  The utility of an epidemiological model of disease spread is dependent upon its ability to be used for forecasting cases or incidence. This ability is itself dependent upon our confidence in the model's prediction accuracy and our understanding of the ways in which the latent states change with time. Thus, we have two linked problems: identifying the distribution of $X_{n}$ at time $n$ given $y_{1:n}$ and finding parameter values, $\hat{\theta}$, which maximize the likelihood of our data. These problems are known as the filtering problem and the inference problem, respectively \cite{crisan, Millar}.
  
   Especially in the case of highly complex environments, both the likelihood function and the transition density of a POMP model can be difficult to write analytically, making these two problems quite hard. Many methods have been developed to surmount the inference and filtering problems, one of which is the particle filter. For the particle filter, we need only supply data, simulators for the initial density and the one time-step transition density of the latent process, and an evaluator for the density of the observation process conditional on the latent process to get maximum likelihood estimates for the model parameters. 
     
   We first initialize a swarm of $M$ particles at time 1, $\{ X_1^m; m \in 1:M \}$, each containing the necessary state information along with a vector of parameter values, $\theta$. Then for each time $n \in 1:N$, we push the particles forward one time-step by drawing from the one time-step transition density, giving us an ensemble of particles representing the prediction distribution at time $n$, $f_{X_n|X_{n-1}}(\cdot | X_{n-1}^m; \theta)$. We weight the particles according to our data by evaluating the measurement density, so $w_{n,m} = f_{Y_n|X_n}(y_n | x_n^m)$. Finally we resample the particles according to these weights, which leads to an ensemble of particles representing the filtering distribution at time $n$, $f_{X_n | Y_{1:n}}(x_n | y_{1:n}; \theta)$.
   
    Because of the assumed independence of the measurement process variables and their dependence upon the latent process variables in a POMP model, we have that:
         \begin{equation}
         \begin{split}
         & \mathcal{L}(\theta) = f_{Y_{1:N}}(y_{1:N}; \theta) \\
         & = \prod_{n=1}^N f_{Y_{n} | Y_{1:n-1}}(y_n | y_{n-1}; \theta) \\
         & = \prod_{n=1}^N \int f_{Y_n | Y_{1:n-1}, X_n}(y_n | y_{1:n-1}, x_n; \theta)f_{X_n | Y_{1:n-1}}(x_n | y_{1:n-1}; \theta) dx_n \\
         & = \prod_{n=1}^N f_{Y_n | X_n}(y_n | x_n)
         \end{split}
         \end{equation}
   
    Notice that the weights used in the particle resampling are $w_{n,m} = f_{Y_n|X_n}(y_n | x_n^m)$ for each particle $m$ at time $n$. If we take the average of $f_{Y_n|X_n}(y_n | x_n^m)$ over all $M$ particles, we can approximate $f_{Y_n|X_n}(y_n | x_n; \theta)$. Therefore: 
    \begin{equation}
    \mathcal{L}(\theta) = \prod_{n=1}^N f_{Y_n | X_n}(y_n | x_n; \theta) \approx \prod_{n=1}^N \frac{1}{M} \sum_{m = 1}^M f_{Y_n|X_n}(y_n | x_n^m) \\
    \end{equation}
   
    In other words, by the Monte Carlo principle we can approximate the conditional likelihood at time $n$ with $w_{n,m}$. Thus the particle filter provides a much easier way to estimate the likelihood of the data given our model and to approximate the distribution of $X_{n}$ at time $n$ given $y_{1:n}$ \cite{King_statinfpomp, Ionides_infpomp, Ionides_if}.
  
  An extension of the particle filter is the improved iterated filtering algorithm (IF2) developed by Ionides et al. \cite{Ionides_infdynsys}. As a plug-and-play method, IF2 is a computationally efficient, simulation-based means for maximum likelihood estimation and inference. IF2 takes an initialized swarm of particles and, using a combination of particle filtering, small changes to the parameter values, and particle resampling, estimates the parameter values which achieve the maximum likelihood \cite{Ionides_infpomp}. With the particle filter and IF2, we are able to approximate solutions to the inference and filtering problems. 
  
\section{Methodology}
\subsection{Model Structure}

  %we wrote modifications to model 1, ran a whole bunch of profiles, mcapped it and found statsig!
  %we found $R_0$ and $R_t$ and fit seasonality splines

 Lee et al. used an SEIAR compartmental model (S: Susceptible, E: Exposed, I: Infectious, A: Asymptomatic Infectious, R: Recovered) for the Haiti cholera epidemic. In their formulation, at a given time point $t$ each compartment contains some unobserved number of individuals from the total population of Haiti. Between two time points $t$ and $t+1$, individuals can transition into the system by birth, out of the system by death, or between compartments at rates that are either specified or estimated. We define these transition rates with the following series of equations:
        \begin{eqnarray}
        \label{SE}
        q_{S_kE_k} = \lambda(t)
        \\
        \label{EI}
        q_{E_kI_k} = \sigma(1 - \theta_0(t))
        \\
        \label{EA}
        q_{E_kA_k} = \sigma\theta_0(t)
        \\
        \label{IR AR}
        q_{I_kR_k} = q_{A_kR_k} = \lambda
        \\
        \label{RS}
        q_{R_kS_k} = \alpha
        \label{vacc}
        q_{S_0S_k} = q_{E_0E_k} = q_{I_0I_k} = q_{A_0A_k} = q_{R_0R_k} = \eta_k(t)
        \\
        \label{birth}
        q_{\cdot S_0} = \mu
        \label{death}
        q_{S_k \cdot} = q_{E_k \cdot} = q_{I_k \cdot} = q_{A_k \cdot} = q_{R_k \cdot} = \delta
        \end{eqnarray}
        
\noindent where $q_{X_kY_k}$ indicates the one time-step transition rate from compartment $X$ to compartment $Y$, and $k \in [0, 10]$ denotes vaccination cohort with $k = 0$ indicating the cohort that did not receive vaccinations. At time $t$, $\eta_k(t)$ is the vaccination rate of cohort $k$, and $\lambda (t)$ is the force of infection, calculated as $\lambda(t) = \frac{\beta(I(t) + (1-\kappa)A(t))^\nu}{N(t)}$. The seasonal transmission term is $\beta = \sum_{i = 1}^6 \beta_i s_i$, which consists of six degree six periodic B-spline terms, $s_{1:6}$, multiplied by estimated seasonality parameters, $\beta_{1:6}$. $I(t)$ is the proportion of the population that is infectious at time $t$, $A(t)$ is the proportion of the population that is asymptomatic at time $t$, $N(t)$ is the population of Haiti at time $t$ with $N_0 = 10911819$, $\kappa = 0.95$ is the assumed reduction in infectiousness of asymptomatic individuals, $\nu$ is an estimated population mixing coefficient, and $\theta_0(t) = 0$ is the proportion of non-vaccinated, exposed individuals who become infected but are asymptomatic. Not dependent on time are $\frac{1}{\alpha} = 8$, the mean duration of natural immunity in years; $\frac{1}{\sigma} = 1.4$, the latent period of cholera in days; $\frac{1}{\gamma} = 2$, the infectious period of cholera in days; $\mu = 0.43$, the birth rate per 1000 individuals per week; and $\delta = 0.14$, the natural death rate per 1000 individuals per week. $q_{\cdot S_0}$ and $q_{X_k \cdot}$ denote the transition rates into and out of the system's compartments via birth and death, respectively. Below is a figure based upon the model diagram from Lee et al. \cite{Lee_supp}. It illustrates the compartmental model with one vaccination cohort. Transitioning out of the system due to death is omitted for legibility.

\subsection{Reproduction}

 The preference for complex over simple models has been growing for several decades despite the fact that it has been shown that complexity is associated with decreases in forecasting accuracy \cite{Green}. Because epidemiological modelling is motivated by the need to accurately forecast disease prevalence to inform policy, we first establish a point of comparison for the evaluation of our model fit and quality. We elect to use a linear, Gaussian autoregressive moving average (ARMA) model of order (2,1) as it is a fairly simple model in which the current state depends only on previous states and white noise \cite{Shumway_ch3}. We can then compare the likelihood of the data under this model to the likelihoods achieved under our proposed models to evaluate whether the additional complexity is truly beneficial.
  
  Lee et al. divided the case data into two periods: epidemic (October 23rd, 2010 through March 31st, 2015) and endemic (April 1st, 2015 through January 12th, 2019) \cite{Lee_supp}. We adopted this breakpoint in our analyses. The ARMA(2,1) benchmark model achieved log-likelihoods of -1616.678, -1139.238, and -2800.808 for the epidemic, endemic, and the combined time period, respectively.
  
 After establishing benchmark log-likelihoods, we attempted to reproduce the results of Lee et al. as closely as possible in order to facilitate the evaluation of their model and parameter estimates. Lee et al. implemented their model in the R package \texttt{pomp} v1.19 and started the model calibration by generating 300 different sets of starting parameter values. They then used trajectory matching followed by iterated filtering to find a maximum likelihood estimate for the parameter values using each of the 300 sets. From the epidemic calibration, they pruned away sets resulting in filtering failures or extreme outlying values. The remaining sets were used as starting values for the endemic calibration in which all parameters were reestimated, excluding the initial state values ($E_0$ and $I_0$) \cite{Lee_supp}.

  We repeated most of this process with some minor changes. We did not perform trajectory matching as it assumes a deterministic latent process, which is not assumed in the forecasting model. Additionally, Lee et al. did not publish their initial starting sets, so we created our own using the schema provided in their supplemental code. We left weeks with missing data as \texttt{NA} rather than \texttt{0} as the \texttt{pomp} package is capable of working with missing data. We also filtered out epidemic parameter sets with $\nu \leq 0.9$ and $\beta_1 \geq 100$ and endemic parameter sets with log-likelihoods of -3000 units or less to avoid outlying parameter values similar to Lee et al.'s pruning process. Our reproduction (\hyperref[fig:A1]{fig. A1}) does seem to visually match the results of Lee et al. in figure S7 of their supplement \cite{Lee_supp}. 

% section add plots for FOI decrease, beta decrease over time

% section add mcap CIs for betat

% section add plots for seasonality over time corresponding to rainfall

% section add mcaps for beta1:6

% section add plots for r_0, r_t

% section -2730 loglik compared to orig joint model, evaluate on aic relative to lee et al

\newpage

\bibliography{bib-thesis}

\end{document}

